{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2.0\n"
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = tf.constant(\"Hello Tensorflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Tensorflow!\n"
     ]
    }
   ],
   "source": [
    "tf.print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 数据流图是一种声明式编程器范式\n",
    "|  编程范式   | 核心思想 | 程序抽象  |  计算过程  | 计算单元  | 擅长领域 |    实现方法  |\n",
    "|    ----    | ----   |   ----   |   ----   |   ----   |  ----  |     ----    |\n",
    "| 声明式编程  |  要什么  | 数学模型  | 表达式变换 |   函数   | 数理逻辑 | 结构化 抽象化 |\n",
    "| 命令式编程  |  怎么做  | 有穷自动机|  状态转换  |   指令   | 业务逻辑 | 过程化 具体化 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斐波拉契数列\n",
    "\n",
    "# 声明式\n",
    "fib = lambda x : 1 if x <= 2 else fib(x - 1) + fib(x - 2)\n",
    "\n",
    "# 命令式\n",
    "def fib(n):\n",
    "    a, b = 1, 1\n",
    "    for i in range(1, n):\n",
    "        a, b = b, a + b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 張量\n",
    "* 在 TensorFlow 中張量（Tensor）表示某種相同數據類型的多維數組。因此，張量有兩個重要屬性：\n",
    "1. 數據類型（如浮點型，整型，字符串）\n",
    "2. 數組形狀（各個維度的大小）0階，1階，2階，3階・・・\n",
    "\n",
    "## Q：張量是什麽\n",
    "* 張量是用來表示多維數據的\n",
    "* 張量是執行操作時的輸入或輸出的數據\n",
    "* 用戶通過執行操作來創建或計算張量\n",
    "* 張量的形狀不一定在編譯時確定，可以在運行時通過形狀推斷計算得出\n",
    "\n",
    "## 在 TensorFlow 中，有几類比較特別的張量，由以下操作產生：\n",
    "* tf.constant //常量\n",
    "* tf.placeholder //佔位符\n",
    "* tf.Variable //變量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 階張量\n",
    "mammal = tf.Variable(\"Elephant\", tf.string)\n",
    "ignition = tf.Variable(451, tf.int16)\n",
    "floating = tf.Variable(3.14159265359, tf.float64)\n",
    "its_complicated = tf.Variable(12.3 - 4.85j, tf.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Variable 'Variable:0' shape=() dtype=string, numpy=b'Elephant'>,\n <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=451>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.1415927>,\n <tf.Variable 'Variable:0' shape=() dtype=complex128, numpy=(12.3-4.85j)>]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "[mammal, ignition, floating, its_complicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 階張量\n",
    "mystr = tf.Variable([\"Hello\", \"World\"], tf.string)\n",
    "cool_numbers = tf.Variable([3.14159, 2.71828], tf.float32)\n",
    "first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)\n",
    "its_very_complicated = tf.Variable([12.3 - 4.85j, 7.5 - 6.23j], tf.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Variable 'Variable:0' shape=(2,) dtype=string, numpy=array([b'Hello', b'World'], dtype=object)>,\n <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([3.14159, 2.71828], dtype=float32)>,\n <tf.Variable 'Variable:0' shape=(5,) dtype=int32, numpy=array([ 2,  3,  5,  7, 11])>,\n <tf.Variable 'Variable:0' shape=(2,) dtype=complex128, numpy=array([12.3-4.85j,  7.5-6.23j])>]"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "[mystr, cool_numbers, first_primes, its_very_complicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 階張量\n",
    "mymat = tf.Variable([[7], [11]], tf.int16)\n",
    "myxor = tf.Variable([[False, True], [True, False]], tf.bool)\n",
    "linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)\n",
    "squarish_squares = tf.Variable([[4, 9], [16, 25]], tf.int32)\n",
    "rank_of_squares = tf.rank(squarish_squares)\n",
    "mymatC = tf.Variable([[7],[11]], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Variable 'Variable:0' shape=(2, 1) dtype=int32, numpy=\n array([[ 7],\n        [11]])>,\n <tf.Variable 'Variable:0' shape=(2, 2) dtype=bool, numpy=\n array([[False,  True],\n        [ True, False]])>,\n <tf.Variable 'Variable:0' shape=(4, 1) dtype=int32, numpy=\n array([[ 4],\n        [ 9],\n        [16],\n        [25]])>,\n <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n array([[ 4,  9],\n        [16, 25]])>,\n <tf.Tensor: shape=(), dtype=int32, numpy=2>,\n <tf.Variable 'Variable:0' shape=(2, 1) dtype=int32, numpy=\n array([[ 7],\n        [11]])>]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "[mymat, myxor, linear_squares, squarish_squares, rank_of_squares, mymatC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 階張量\n",
    "my_image = tf.zeros([10, 299, 299, 3]) # batch x height x with x color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 變量\n",
    "* TensorFlow 變量（Variable）的主要作用是維護特定節點的狀態，如深度學習或機器學習的模型參數。\n",
    "* tf.Variable 方法是操作，返回值是變量（特殊張量）\n",
    "* 通過 tf.Variable 方法創建的變量，與張量一樣，可以作爲操作的輸入和輸出。不同之處在於:\n",
    "    * 張量的生命周期通常隨依賴的計算完成而結束，内存也隨即釋放。\n",
    "    * 變量則常駐内存，在每一步訓練時不斷更新其值，以實現模型參數的更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 操作\n",
    "TensorFlow 用数据流图表示算法模型。数据流图由节点和有向边组成，每个节点均对应一个具体的操作。因此，操作是模型功能的实际载体。\n",
    "数据流图中的节点按照功能不同可以分为3种\n",
    "* __存储节点__ ：有状态的变量操作，通常用来存储模型参数\n",
    "* __计算节点__ ：无状态的计算或控制操作，主要负责算法逻辑表达或流程控制\n",
    "* __数据节点__ ：数据的占位符操作，用于描述图外输入数据的属性\n",
    "\n",
    "## 占位符操作\n",
    "TensorFlow使用占位符操作表示图外输入的数据，如训练和测试数据。\n",
    "TensorFlow数据流图描述了算法模型的计算拓扑，其中的各个操作（节点）都是抽象的函数映射或数学表达式。\n",
    "换句话说，数据流图本身是一个具有计算拓扑和内部结构的“壳”。在用户向数据流图填充数据前，图中并没有真正执行任何计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}