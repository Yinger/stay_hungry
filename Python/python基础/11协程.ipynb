{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "crawling url_1\nOK url_1\ncrawling url_2\nOK url_2\ncrawling url_3\nOK url_3\ncrawling url_4\nOK url_4\nWall time: 10 s\n"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def crawl_page1(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    time.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "def main(urls):\n",
    "    for url in urls:\n",
    "        crawl_page1(url)\n",
    "\n",
    "%time main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "crawling url_1\nOK url_1\ncrawling url_2\nOK url_2\ncrawling url_3\nOK url_3\ncrawling url_4\nOK url_4\nWall time: 10.004764318466187 s\n"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "\n",
    "async def crawl_page2(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    for url in urls:\n",
    "        await crawl_page2(url)\n",
    "\n",
    "# %time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\n",
    "start = time.time()\n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 协程的执行\n",
    "* 首先，我们可以通过 await 来调用\n",
    "    * await 执行的效果，和 Python 正常执行是一样的，也就是说程序会阻塞在这里，进入被调用的协程函数，执行完毕返回后再继续，而这也是 await 的字面意思。代码中 await asyncio.sleep(sleep_time) 会在这里休息若干秒，await crawl_page(url) 则会执行 crawl_page() 函数\n",
    "* 其次，我们可以通过 asyncio.create_task() 来创建任务\n",
    "* 最后，我们需要 asyncio.run 来触发运行\n",
    "    * asyncio.run 这个函数是 Python 3.7 之后才有的特性，可以让 Python 的协程接口变得非常简单，你不用去理会事件循环怎么定义和怎么使用的问题\n",
    "    * 一个非常好的编程规范是，asyncio.run(main()) 作为主程序的入口函数，在程序运行周期内，只调用一次 asyncio.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务（Task）\n",
    "有了协程对象后，便可以通过 asyncio.create_task 来创建任务。任务创建后很快就会被调度执行，这样，我们的代码也不会阻塞在任务这里。所以，我们要等所有任务都结束才行，用for task in tasks: await task 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "crawling url_1\ncrawling url_2\ncrawling url_3\ncrawling url_4\nOK url_1\nOK url_2\nOK url_3\nOK url_4\nWall time: 4.0057594776153564 s\n"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "\n",
    "async def crawl_page3(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page3(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task\n",
    "\n",
    "# %time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\n",
    "start = time.time()\n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于执行 tasks，还有另一种做法:\n",
    "*tasks 解包列表，将列表变成了函数的参数；与之对应的是， ** dict 将字典变成了函数的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "crawling url_1\ncrawling url_2\ncrawling url_3\ncrawling url_4\nOK url_1\nOK url_2\nOK url_3\nOK url_4\nWall time: 4.003801345825195 s\n"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "\n",
    "async def crawl_page4(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page4(url)) for url in urls]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# %time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))\n",
    "start = time.time()\n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解密协程运行时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before await\nworker_1 start\nworker_1 done\nawaited worker_1\nworker_2 start\nworker_2 done\nawaited worker_2\nWall time: 3.0014841556549072 s\n"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "\n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 done')\n",
    "\n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 done')\n",
    "\n",
    "async def main():\n",
    "    print('before await')\n",
    "    await worker_1()\n",
    "    print('awaited worker_1')\n",
    "    await worker_2()\n",
    "    print('awaited worker_2')\n",
    "\n",
    "# %time asyncio.run(main())\n",
    "start = time.time()\n",
    "await main()\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before await\nworker_1 start\nworker_2 start\nworker_1 done\nawaited worker_1\nworker_2 done\nawaited worker_2\nWall time: 2.003756046295166 s\n"
    }
   ],
   "source": [
    "# 1. asyncio.run(main())，程序进入 main() 函数，事件循环开启；\n",
    "# 2. task1 和 task2 任务被创建，并进入事件循环等待运行；运行到 print，输出 'before await'；\n",
    "# 3. await task1 执行，用户选择从当前的主任务中切出，事件调度器开始调度 worker_1；\n",
    "# 4. worker_1 开始运行，运行 print 输出'worker_1 start'，然后运行到 await asyncio.sleep(1)， 从当前任务切出，事件调度器开始调度 worker_2；\n",
    "# 5. worker_2 开始运行，运行 print 输出 'worker_2 start'，然后运行 await asyncio.sleep(2) 从当前任务切出；\n",
    "# 6. 以上所有事件的运行时间，都应该在 1ms 到 10ms 之间，甚至可能更短，事件调度器从这个时候开始暂停调度；\n",
    "# 7. 一秒钟后，worker_1 的 sleep 完成，事件调度器将控制权重新传给 task_1，输出 'worker_1 done'，task_1 完成任务，从事件循环中退出；\n",
    "# 8. await task1 完成，事件调度器将控制器传给主任务，输出 'awaited worker_1'，·然后在 await task2 处继续等待；\n",
    "# 9. 两秒钟后，worker_2 的 sleep 完成，事件调度器将控制权重新传给 task_2，输出 'worker_2 done'，task_2 完成任务，从事件循环中退出；\n",
    "# 10. 主任务输出 'awaited worker_2'，协程全任务结束，事件循环结束。\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def worker_1():\n",
    "    print('worker_1 start')\n",
    "    await asyncio.sleep(1)\n",
    "    print('worker_1 done')\n",
    "\n",
    "async def worker_2():\n",
    "    print('worker_2 start')\n",
    "    await asyncio.sleep(2)\n",
    "    print('worker_2 done')\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(worker_1())\n",
    "    task2 = asyncio.create_task(worker_2())\n",
    "    print('before await')\n",
    "    await task1\n",
    "    print('awaited worker_1')\n",
    "    await task2\n",
    "    print('awaited worker_2')\n",
    "\n",
    "# %time asyncio.run(main())\n",
    "start = time.time()\n",
    "await main()\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1, ZeroDivisionError('division by zero'), CancelledError()]\nWall time: 2.0036962032318115 s\n"
    }
   ],
   "source": [
    "# 接下来，我们进阶一下。\n",
    "# 如果我们想给某些协程任务限定运行时间，一旦超时就取消，又该怎么做呢？\n",
    "# 再进一步，如果某些协程运行时出现错误，又该怎么处理呢？\n",
    "# 同样的，来看代码。\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def worker_1():\n",
    "    await asyncio.sleep(1)\n",
    "    return 1\n",
    "\n",
    "async def worker_2():\n",
    "    await asyncio.sleep(2)\n",
    "    return 2 / 0\n",
    "\n",
    "async def worker_3():\n",
    "    await asyncio.sleep(3)\n",
    "    return 3\n",
    "\n",
    "async def main():\n",
    "    task_1 = asyncio.create_task(worker_1())\n",
    "    task_2 = asyncio.create_task(worker_2())\n",
    "    task_3 = asyncio.create_task(worker_3())\n",
    "\n",
    "    await asyncio.sleep(2)\n",
    "    task_3.cancel()\n",
    "\n",
    "    res = await asyncio.gather(task_1, task_2, task_3, return_exceptions=True) # 注意:return_exceptions=True 如果不设置这个参数，错误就会完整地 throw 到我们这个执行层，从而需要 try except 来捕捉，这也就意味着其他还没被执行的任务会被全部取消掉。\n",
    "    print(res)\n",
    "\n",
    "# %time asyncio.run(main())\n",
    "start = time.time()\n",
    "await main()\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用协程来实现一个经典的生产者消费者模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "producer_1 put a val: 4\nproducer_2 put a val: 2\nconsumer_1 get a val: 4\nconsumer_2 get a val: 2\nproducer_1 put a val: 9\nproducer_2 put a val: 10\nconsumer_2 get a val: 9\nconsumer_1 get a val: 10\nproducer_1 put a val: 6\nproducer_2 put a val: 1\nconsumer_1 get a val: 6\nconsumer_2 get a val: 1\nproducer_1 put a val: 7\nproducer_2 put a val: 3\nconsumer_2 get a val: 7\nconsumer_1 get a val: 3\nproducer_1 put a val: 5\nproducer_2 put a val: 2\nconsumer_1 get a val: 5\nconsumer_2 get a val: 2\nWall time: 9.994991540908813 s\n"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def consumer(queue, id):\n",
    "    while True:\n",
    "        val = await queue.get()\n",
    "        print('{} get a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def producer(queue, id):\n",
    "    for i in range(5):\n",
    "        val = random.randint(1, 10)\n",
    "        await queue.put(val)\n",
    "        print('{} put a val: {}'.format(id, val))\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def main():\n",
    "    queue = asyncio.Queue()\n",
    "\n",
    "    consumer_1 = asyncio.create_task(consumer(queue, 'consumer_1'))\n",
    "    consumer_2 = asyncio.create_task(consumer(queue, 'consumer_2'))\n",
    "\n",
    "    producer_1 = asyncio.create_task(producer(queue, 'producer_1'))\n",
    "    producer_2 = asyncio.create_task(producer(queue, 'producer_2'))\n",
    "\n",
    "    await asyncio.sleep(10)\n",
    "    consumer_1.cancel()\n",
    "    consumer_2.cancel()\n",
    "    \n",
    "    await asyncio.gather(consumer_1, consumer_2, producer_1, producer_2, return_exceptions=True)\n",
    "\n",
    "# %time asyncio.run(main())\n",
    "start = time.time()\n",
    "await main()\n",
    "end = time.time()\n",
    "print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实战：豆瓣近日推荐电影爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install beautifulsoup4\n",
    "# pip install lxml\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def main():\n",
    "#     url = \"https://movie.douban.com/cinema/later/beijing/\"\n",
    "#     init_page = requests.get(url).content\n",
    "#     init_soup = BeautifulSoup(init_page, 'lxml')\n",
    "\n",
    "#     all_movies = init_soup.find('div', id=\"showing-soon\")\n",
    "#     for each_movie in all_movies.find_all('div', class_=\"item\"):\n",
    "#         all_a_tag = each_movie.find_all('a')\n",
    "#         all_li_tag = each_movie.find_all('li')\n",
    "\n",
    "#         movie_name = all_a_tag[1].text\n",
    "#         url_to_fetch = all_a_tag[1]['href']\n",
    "#         movie_date = all_li_tag[0].text\n",
    "\n",
    "#         response_item = requests.get(url_to_fetch).content\n",
    "#         soup_item = BeautifulSoup(response_item, 'lxml')\n",
    "#         img_tag = soup_item.find('img')\n",
    "\n",
    "#         print('{} {} {}'.format(movie_name, movie_date, img_tag['src']))\n",
    "\n",
    "# # %time main()\n",
    "# start = time.time()\n",
    "# await main()\n",
    "# end = time.time()\n",
    "# print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'header' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-356852d71b28>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Wall time: {} s'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-356852d71b28>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0minit_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_page\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmovie_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murls_to_fetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mall_movies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"showing-soon\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-356852d71b28>\u001b[0m in \u001b[0;36mfetch_content\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     ) as session:\n\u001b[0;32m     11\u001b[0m         \u001b[1;32masync\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'header' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# import time\n",
    "# import asyncio\n",
    "# import aiohttp\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# async def fetch_content(url):\n",
    "#     async with aiohttp.ClientSession(\n",
    "#         headers=header, connector=aiohttp.TCPConnector(ssl=False)\n",
    "#     ) as session:\n",
    "#         async with session.get(url) as response:\n",
    "#             return await response.text()\n",
    "\n",
    "# async def main():\n",
    "#     url = \"https://movie.douban.com/cinema/later/beijing/\"\n",
    "#     init_page = await fetch_content(url)\n",
    "#     init_soup = BeautifulSoup(init_page, 'lxml')\n",
    "\n",
    "#     movie_names, urls_to_fetch, movie_dates = [], [], []\n",
    "\n",
    "#     all_movies = init_soup.find('div', id=\"showing-soon\")\n",
    "#     for each_movie in all_movies.find_all('div', class_=\"item\"):\n",
    "#         all_a_tag = each_movie.find_all('a')\n",
    "#         all_li_tag = each_movie.find_all('li')\n",
    "\n",
    "#         movie_names.append(all_a_tag[1].text)\n",
    "#         urls_to_fetch.append(all_a_tag[1]['href'])\n",
    "#         movie_dates.append(all_li_tag[0].text)\n",
    "\n",
    "#     tasks = [fetch_content(url) for url in urls_to_fetch]\n",
    "#     pages = await asyncio.gather(*tasks)\n",
    "\n",
    "#     for movie_name, movie_date, page in zip(movie_names, movie_dates, pages):\n",
    "#         soup_item = BeautifulSoup(page, 'lxml')\n",
    "#         img_tag = soup_item.find('img')\n",
    "\n",
    "#         print('{} {} {}'.format(movie_name, movie_date, img_tag['src']))\n",
    "\n",
    "# # %time asyncio.run(main())\n",
    "# start = time.time()\n",
    "# await main()\n",
    "# end = time.time()\n",
    "# print('Wall time: {} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "venv",
   "display_name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}