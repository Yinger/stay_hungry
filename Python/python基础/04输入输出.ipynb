{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件输入输出\n",
    "\n",
    "### NLP(自然语言处理) 任务的基本步骤\n",
    "1. 读取文件；\n",
    "2. 去除所有标点符号和换行符，并把所有大写变成小写；\n",
    "3. 合并相同的词，统计每个词出现的频率，并按照词频从大到小排序；\n",
    "4. 将结果按行输出到文件 04输入输出out.txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse(text):\n",
    "    # 使用正则表达式去除标点符号和换行符\n",
    "    text = re.sub(r'[^\\w ]', ' ', text)\n",
    "\n",
    "    # 转为小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 生成所有单词的列表\n",
    "    word_list = text.split(' ')\n",
    "    \n",
    "    # 去除空白单词\n",
    "    word_list = filter(None, word_list)\n",
    "    \n",
    "    # 生成单词和词频的字典\n",
    "    word_cnt = {}\n",
    "    for word in word_list:\n",
    "        if word not in word_cnt:\n",
    "            word_cnt[word] = 0\n",
    "        word_cnt[word] += 1\n",
    "    \n",
    "    # 按照词频排序\n",
    "    sorted_word_cnt = sorted(word_cnt.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "    return sorted_word_cnt\n",
    "\n",
    "with open('04输入输出in.txt', 'r') as fin:\n",
    "    text = fin.read()\n",
    "\n",
    "word_and_freq = parse(text)\n",
    "\n",
    "with open('04输入输出out.txt', 'w') as fout:\n",
    "    for word, freq in word_and_freq:\n",
    "        fout.write('{} {}\\n'.format(word, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 用 open() 函数拿到文件的指针。其中，第一个参数指定文件位置（相对位置或者绝对位置）；第二个参数，如果是 'r'表示读取，如果是'w' 则表示写入，当然也可以用 'rw' ，表示读写都要。a 则是一个不太常用（但也很有用）的参数，表示追加（append），这样打开的文件，如果需要写入，会从原始文件的最末尾开始写入\n",
    "* 在拿到指针后，我们可以通过 read() 函数，来读取文件的全部内容。代码 text = fin.read() ，即表示把文件所有内容读取到内存中，并赋值给变量 text\n",
    "* with 语句 : open() 函数对应于 close() 函数，也就是说，如果你打开了文件，在完成读取任务后，就应该立刻关掉它。而如果你使用了 with 语句，就不需要显式调用 close()。在 with 的语境下任务执行完毕后，close() 函数会被自动调用，代码也简洁很多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after json serialization\n",
      "type of params_str = <class 'str'>, params_str = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n",
      "after json deserialization\n",
      "type of original_params = <class 'dict'>, original_params = {'symbol': '123456', 'type': 'limit', 'price': 123.4, 'amount': 23}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "params = {\n",
    "    'symbol': '123456',\n",
    "    'type': 'limit',\n",
    "    'price': 123.4,\n",
    "    'amount': 23\n",
    "}\n",
    "\n",
    "# json.dumps() 这个函数，接受 Python 的基本数据类型，然后将其序列化为 string\n",
    "params_str = json.dumps(params)\n",
    "\n",
    "print('after json serialization')\n",
    "print('type of params_str = {}, params_str = {}'.format(type(params_str), params))\n",
    "\n",
    "# json.loads() 这个函数，接受一个合法字符串，然后将其反序列化为 Python 的基本数据类型\n",
    "original_params = json.loads(params_str)\n",
    "\n",
    "print('after json deserialization')\n",
    "print('type of original_params = {}, original_params = {}'.format(type(original_params), original_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业：重写 NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 9), ('to', 9), ('the', 8), ('and', 7), ('your', 6), ('of', 6), ('others', 5), ('with', 4), ('do', 4), ('are', 3), ('be', 3), ('word', 3), ('what', 3), ('avoid', 3), ('t', 3), ('is', 3), ('as', 3), ('best', 3), ('four', 2), ('agreements', 2), ('a', 2), ('life', 2), ('speak', 2), ('say', 2), ('don', 2), ('their', 2), ('own', 2), ('when', 2), ('can', 2), ('moment', 2), ('will', 2), ('self', 2), ('living', 1), ('changing', 1), ('journey', 1), ('1', 1), ('impeccable', 1), ('integrity', 1), ('only', 1), ('mean', 1), ('using', 1), ('against', 1), ('yourself', 1), ('or', 1), ('gossip', 1), ('about', 1), ('use', 1), ('power', 1), ('in', 1), ('direction', 1), ('truth', 1), ('love', 1), ('2', 1), ('take', 1), ('anything', 1), ('personally', 1), ('nothing', 1), ('because', 1), ('projection', 1), ('reality', 1), ('dream', 1), ('immune', 1), ('opinions', 1), ('actions', 1), ('won', 1), ('victim', 1), ('needless', 1), ('suffering', 1), ('3', 1), ('make', 1), ('assumptions', 1), ('find', 1), ('courage', 1), ('ask', 1), ('questions', 1), ('express', 1), ('really', 1), ('want', 1), ('communicate', 1), ('clearly', 1), ('misunderstandings', 1), ('sadness', 1), ('drama', 1), ('just', 1), ('this', 1), ('one', 1), ('agreement', 1), ('completely', 1), ('transform', 1), ('4', 1), ('always', 1), ('going', 1), ('change', 1), ('from', 1), ('it', 1), ('different', 1), ('healthy', 1), ('opposed', 1), ('sick', 1), ('under', 1), ('any', 1), ('circumstance', 1), ('simply', 1), ('judgment', 1), ('abuse', 1), ('regret', 1)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "BUFFER_SIZE = 100 # 一次最多读取的字符长度\n",
    "\n",
    "def parse_to_word_list(text, last_word, word_list):\n",
    "    text = re.sub(r'[^\\w ]', ' ', last_word + text)\n",
    "    text = text.lower()\n",
    "    cur_word_list = text.split(' ')\n",
    "    cur_word_list, last_word = cur_word_list[:-1], cur_word_list[-1]\n",
    "    word_list += filter(None, cur_word_list)\n",
    "    return last_word\n",
    "\n",
    "def solve():\n",
    "    with open('04输入输出in.txt', 'r') as fin:\n",
    "        word_list, last_word = [], ''\n",
    "        while True:\n",
    "            text = fin.read(BUFFER_SIZE)\n",
    "            if not text: \n",
    "                break\n",
    "            last_word = parse_to_word_list(text, last_word, word_list)\n",
    "            \n",
    "        word_cnt = {}\n",
    "        for word in word_list:\n",
    "            if word not in word_cnt:\n",
    "                word_cnt[word] = 0\n",
    "            word_cnt[word] += 1\n",
    "    \n",
    "        sorted_word_cnt = sorted(word_cnt.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        return sorted_word_cnt\n",
    "\n",
    "print(solve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
